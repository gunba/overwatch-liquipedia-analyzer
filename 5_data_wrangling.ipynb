{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files: 100%|██████████| 3685/3685 [00:00<00:00, 4272.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Load all JSON files from the tournaments_data folder\n",
    "data_folder = \"tournaments_data\"\n",
    "all_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.json')]\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "tournament_info_list = []\n",
    "team_members_list = []\n",
    "match_cards_list = []\n",
    "maps_list = []\n",
    "\n",
    "# Helper function to extract map data\n",
    "def extract_map_data(match_id, match_data):\n",
    "    maps = []\n",
    "    for key, value in match_data.items():\n",
    "        if key.startswith('map'):\n",
    "            map_num = key[3:]\n",
    "            map_info = value if isinstance(value, dict) else {}\n",
    "            map_info['map_num'] = map_num\n",
    "            map_info['match_card_id'] = match_id\n",
    "            maps.append(map_info)\n",
    "    return maps\n",
    "\n",
    "# ID counters\n",
    "tournament_id_counter = 1\n",
    "team_id_counter = 1\n",
    "match_id_counter = 1\n",
    "\n",
    "# Process each file with a progress bar\n",
    "for file in tqdm(all_files, desc=\"Processing JSON files\"):\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "        # Extract tournament_info\n",
    "        tournament_info = data.get(\"tournament_info\", [])\n",
    "        if tournament_info:\n",
    "            tournament_info = tournament_info[0]\n",
    "        else:\n",
    "            tournament_info = {}\n",
    "        \n",
    "        tournament_info[\"tournament_id\"] = tournament_id_counter\n",
    "        tournament_info_list.append(tournament_info)\n",
    "        \n",
    "        # Extract team members\n",
    "        team_cards = data.get(\"team_cards\", [])\n",
    "        for team in team_cards:\n",
    "            if not team.get(\"team\"):\n",
    "                continue\n",
    "            team_id = team_id_counter\n",
    "            team_id_counter += 1\n",
    "            members = team.get(\"members\", [])\n",
    "            for member in members:\n",
    "                if not member.get(\"name\"):\n",
    "                    continue\n",
    "                team_member_info = {\n",
    "                    \"team\": team.get(\"team\", \"\"),\n",
    "                    \"tournament_id\": tournament_id_counter,\n",
    "                    \"team_id\": team_id\n",
    "                }\n",
    "                team_member_info.update(member)  # Add all keys from member\n",
    "                team_members_list.append(team_member_info)\n",
    "        \n",
    "        # Extract match cards\n",
    "        match_cards = data.get(\"match_cards\", [])\n",
    "        for match in match_cards:\n",
    "            if not match.get(\"winner\"):\n",
    "                continue\n",
    "            match_id = match_id_counter\n",
    "            match_id_counter += 1\n",
    "            match['tournament_id'] = tournament_id_counter\n",
    "            match['match_card_id'] = match_id\n",
    "            match_cards_list.append(match)\n",
    "            \n",
    "            # Extract maps data from match cards\n",
    "            maps = extract_map_data(match_id, match)\n",
    "            maps_list.extend(maps)\n",
    "    \n",
    "    tournament_id_counter += 1\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "tournament_info_df = pd.DataFrame(tournament_info_list)\n",
    "team_members_df = pd.DataFrame(team_members_list)\n",
    "match_cards_df = pd.DataFrame(match_cards_list)\n",
    "maps_df = pd.DataFrame(maps_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\AppData\\Local\\Temp\\ipykernel_19400\\1363133916.py:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: np.nan if isinstance(x, str) and x.strip() == '' else x)\n"
     ]
    }
   ],
   "source": [
    "# Convert all empty whitespace values to NaN\n",
    "def convert_whitespace_to_nan(df):\n",
    "    return df.applymap(lambda x: np.nan if isinstance(x, str) and x.strip() == '' else x)\n",
    "\n",
    "tournament_info_df = convert_whitespace_to_nan(tournament_info_df)\n",
    "team_members_df = convert_whitespace_to_nan(team_members_df)\n",
    "match_cards_df = convert_whitespace_to_nan(match_cards_df)\n",
    "maps_df = convert_whitespace_to_nan(maps_df)\n",
    "\n",
    "# Function to validate date\n",
    "def is_valid_date(date_str):\n",
    "    try:\n",
    "        pd.to_datetime(date_str, format=\"%Y-%m-%d\", errors='raise')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Function to validate date and convert to datetime\n",
    "def to_datetime(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%Y-%m-%d\", errors='raise')\n",
    "    except ValueError:\n",
    "        return pd.NaT\n",
    "    \n",
    "# Function to compare dates and return the least recent valid date\n",
    "def get_least_recent_date(dates):\n",
    "    valid_dates = [date for date in dates if pd.notna(to_datetime(date))]\n",
    "    return min(valid_dates) if valid_dates else None\n",
    "\n",
    "# Calculate agg_date\n",
    "tournament_info_df['agg_date'] = tournament_info_df.apply(lambda row: get_least_recent_date(\n",
    "    [row.get('date', ''), row.get('sdate', ''), row.get('edate', '')]\n",
    "), axis=1)\n",
    "\n",
    "# Convert agg_date to just the date part (YYYY-MM-DD)\n",
    "#tournament_info_df['agg_date'] = pd.to_datetime(tournament_info_df['agg_date']).dt.date\n",
    "\n",
    "# Drop rows with no valid date\n",
    "tournament_info_df = tournament_info_df[tournament_info_df['agg_date'].notna()]\n",
    "\n",
    "# Sort by agg_date and create the date_order column\n",
    "tournament_info_df = tournament_info_df.sort_values(by='agg_date').reset_index(drop=True)\n",
    "tournament_info_df['date_order'] = tournament_info_df.index + 1\n",
    "\n",
    "# Drop rows where liquipediatier column is 5.0\n",
    "tournament_info_df = tournament_info_df[tournament_info_df['liquipediatier'] != 5.0]\n",
    "\n",
    "# Keep only specified columns\n",
    "columns_to_keep = ['name', 'series', 'organizer', 'type', 'city', 'country', 'prizepool', 'prizepoolusd', 'format', 'date', 'sdate', 'edate', 'liquipediatier', 'team_number', 'agg_date', 'tournament_id', 'date_order']\n",
    "tournament_info_df = tournament_info_df[columns_to_keep]\n",
    "\n",
    "# Process match_cards_df\n",
    "# Fill missing date values from tournament agg_date\n",
    "match_cards_df = match_cards_df.merge(tournament_info_df[['tournament_id', 'agg_date']], on='tournament_id', how='left', suffixes=('', '_tournament'))\n",
    "match_cards_df['date'] = match_cards_df.apply(lambda row: row['date'] if not pd.isna(row['date']) else row['agg_date'], axis=1)\n",
    "match_cards_df.drop(columns=['agg_date'], inplace=True)\n",
    "\n",
    "# Drop rows without opponent1 or opponent2\n",
    "match_cards_df = match_cards_df.dropna(subset=['opponent1', 'opponent2'])\n",
    "\n",
    "# Drop rows where opponent1 or opponent2 is 'BYE'\n",
    "match_cards_df = match_cards_df[\n",
    "    (match_cards_df['opponent1'] != 'BYE') & (match_cards_df['opponent2'] != 'BYE')\n",
    "]\n",
    "\n",
    "# Keep only specified columns\n",
    "columns_to_keep = ['date', 'date_timezone', 'opponent1', 'opponent2', 'opponent1_score', 'opponent2_score', 'winner', 'format', 'date_time', 'key', 'tournament_id', 'match_card_id']\n",
    "match_cards_df = match_cards_df[columns_to_keep]\n",
    "\n",
    "# Keep only specified columns\n",
    "columns_to_keep = ['map', 'mode', 'score1', 'score2', 'winner', 'map_num', 'match_card_id'] \n",
    "maps_df = maps_df[columns_to_keep]\n",
    "\n",
    "# Drop related entries in other dataframes for removed tournaments\n",
    "valid_tournament_ids = set(tournament_info_df['tournament_id'])\n",
    "\n",
    "# Drop match_cards_df records where tournament_id is not in tournament_id in tournament_info_df\n",
    "match_cards_df = match_cards_df[match_cards_df['tournament_id'].isin(valid_tournament_ids)]\n",
    "\n",
    "# Drop maps where match_card_id is not in match_cards_df.match_card_id\n",
    "valid_match_card_ids = set(match_cards_df['match_card_id'])\n",
    "maps_df = maps_df[maps_df['match_card_id'].isin(valid_match_card_ids)]\n",
    "\n",
    "# Drop teams where tournament_id is not in tournament_info_df\n",
    "team_members_df = team_members_df[team_members_df['tournament_id'].isin(valid_tournament_ids)]\n",
    "\n",
    "# Track if each tournament has players or not for later.\n",
    "tournament_info_df['has_players'] = tournament_info_df['tournament_id'].isin(team_members_df['tournament_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16677/16677 [00:04<00:00, 3835.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 1. Max Index 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8516/8516 [00:07<00:00, 1085.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.98. Max Index 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6252/6252 [00:05<00:00, 1045.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.96. Max Index 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6243/6243 [00:05<00:00, 1142.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.94. Max Index 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6243/6243 [00:05<00:00, 1112.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.9199999999999999. Max Index 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6185/6185 [00:05<00:00, 1168.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.8999999999999999. Max Index 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6071/6071 [00:06<00:00, 1005.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.8799999999999999. Max Index 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6024/6024 [00:06<00:00, 966.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.8599999999999999. Max Index 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5957/5957 [00:05<00:00, 1075.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.8399999999999999. Max Index 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5817/5817 [00:06<00:00, 924.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.8199999999999998. Max Index 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5570/5570 [00:06<00:00, 894.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.7999999999999998. Max Index 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5323/5323 [00:06<00:00, 815.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.7799999999999998. Max Index 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4862/4862 [00:06<00:00, 707.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.7599999999999998. Max Index 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4628/4628 [00:08<00:00, 569.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.7399999999999998. Max Index 315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4415/4415 [00:09<00:00, 466.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.7199999999999998. Max Index 473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4215/4215 [00:11<00:00, 356.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from difflib import get_close_matches\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "\n",
    "# Set up tqdm with pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load the acronym map\n",
    "with open('acronym_map.json', 'r') as file:\n",
    "    acronym_map = json.load(file)\n",
    "\n",
    "# Map opponent acronyms to full names, retain original name if not found\n",
    "def map_acronyms(team_name):\n",
    "    return acronym_map.get(team_name, team_name)\n",
    "\n",
    "match_cards_df['opponent1'] = match_cards_df['opponent1'].apply(map_acronyms)\n",
    "match_cards_df['opponent2'] = match_cards_df['opponent2'].apply(map_acronyms)\n",
    "\n",
    "# Terms to remove\n",
    "terms_to_remove = ['GAMING', 'TEAM', 'ESPORTS', 'ESPORT', 'CLUB']\n",
    "\n",
    "def clean_team_name(name):\n",
    "    # Remove specified terms\n",
    "    for term in terms_to_remove:\n",
    "        name = name.replace(term, '')\n",
    "    # Remove non-alphanumeric characters\n",
    "    name = re.sub(r'\\W+', '', name)\n",
    "    return name.strip().upper()  # Convert to upper case for uniformity\n",
    "\n",
    "# Create clean_team column in team_members_df\n",
    "team_members_df['clean_team'] = team_members_df['team'].apply(clean_team_name)\n",
    "tournament_id_to_date_order = tournament_info_df.set_index('tournament_id')['date_order'].to_dict()\n",
    "tournament_id_to_liquipediatier = tournament_info_df.set_index('tournament_id')['liquipediatier'].to_dict()\n",
    "tournament_id_to_agg_date = tournament_info_df.set_index('tournament_id')['agg_date'].to_dict()\n",
    "\n",
    "# Add date_order, liquipediatier, and agg_date to match_cards_df using the mapping\n",
    "match_cards_df['date_order'] = match_cards_df['tournament_id'].map(tournament_id_to_date_order)\n",
    "match_cards_df['liquipediatier'] = match_cards_df['tournament_id'].map(tournament_id_to_liquipediatier)\n",
    "match_cards_df['agg_date'] = match_cards_df['tournament_id'].map(tournament_id_to_agg_date)\n",
    "\n",
    "# Create unique_teams dataframe directly from team_members_df\n",
    "unique_teams = team_members_df[['clean_team', 'team_id', 'tournament_id']].drop_duplicates()\n",
    "\n",
    "# Add date_order, liquipediatier, and agg_date to unique_teams using the mapping\n",
    "unique_teams['date_order'] = unique_teams['tournament_id'].map(tournament_id_to_date_order)\n",
    "unique_teams['liquipediatier'] = unique_teams['tournament_id'].map(tournament_id_to_liquipediatier)\n",
    "unique_teams['agg_date'] = unique_teams['tournament_id'].map(tournament_id_to_agg_date)\n",
    "\n",
    "# Initial matching within the same tournament\n",
    "def find_closest_team_id_within_tournament(row, unique_teams, threshold=0.8):\n",
    "    tournament_teams = unique_teams[unique_teams['tournament_id'] == row['tournament_id']]\n",
    "    team_names = tournament_teams['clean_team'].tolist()\n",
    "    team_ids = tournament_teams['team_id'].tolist()\n",
    "    \n",
    "    best_team1_id, best_team2_id = None, None\n",
    "    \n",
    "    if team_names:\n",
    "        matches1 = get_close_matches(row['clean_opponent1'], team_names, n=1, cutoff=threshold)\n",
    "        matches2 = get_close_matches(row['clean_opponent2'], team_names, n=1, cutoff=threshold)\n",
    "        \n",
    "        if matches1:\n",
    "            best_team1_id = team_ids[team_names.index(matches1[0])]\n",
    "        if matches2:\n",
    "            best_team2_id = team_ids[team_names.index(matches2[0])]\n",
    "    \n",
    "    return best_team1_id, best_team2_id\n",
    "\n",
    "# Apply initial matching with progress bar\n",
    "match_cards_df['clean_opponent1'] = match_cards_df['opponent1'].apply(clean_team_name)\n",
    "match_cards_df['clean_opponent2'] = match_cards_df['opponent2'].apply(clean_team_name)\n",
    "\n",
    "# Initial matching\n",
    "team_ids = match_cards_df.progress_apply(lambda row: find_closest_team_id_within_tournament(row, unique_teams, 0.8), axis=1)\n",
    "match_cards_df[['team1_id', 'team2_id']] = pd.DataFrame(team_ids.tolist(), index=match_cards_df.index)\n",
    "\n",
    "# Function to find the closest matching team_id with index distance, liquipediatier constraint, and identical agg_date check\n",
    "def find_closest_team_id_with_index_distance(row, unique_teams, threshold=0.8, max_index=1):\n",
    "    date_order = row['date_order']\n",
    "    agg_date = row['agg_date']\n",
    "    tier = row['liquipediatier']\n",
    "    date_range = range(date_order - max_index, date_order + 1)  # Looking backward in time\n",
    "    \n",
    "    candidate_teams = unique_teams[((unique_teams['date_order'].isin(date_range)) | \n",
    "                                   (unique_teams['agg_date'] == agg_date)) & \n",
    "                                   (unique_teams['liquipediatier'].between(tier - 1, tier + 1))]\n",
    "    team_names = candidate_teams['clean_team'].tolist()\n",
    "    team_ids = candidate_teams['team_id'].tolist()\n",
    "    \n",
    "    best_team1_id, best_team2_id = None, None\n",
    "    \n",
    "    if team_names:\n",
    "        matches1 = get_close_matches(row['clean_opponent1'], team_names, n=1, cutoff=threshold)\n",
    "        matches2 = get_close_matches(row['clean_opponent2'], team_names, n=1, cutoff=threshold)\n",
    "        \n",
    "        if matches1:\n",
    "            best_team1_id = team_ids[team_names.index(matches1[0])]\n",
    "        if matches2:\n",
    "            best_team2_id = team_ids[team_names.index(matches2[0])]\n",
    "    \n",
    "    return best_team1_id, best_team2_id\n",
    "\n",
    "# Loop to progressively reduce threshold and increase index distance\n",
    "def progressively_match_teams(match_cards_df, unique_teams):\n",
    "    threshold = 1\n",
    "    max_index = 1\n",
    "\n",
    "    while True:\n",
    "        missing_team1_ids = match_cards_df['team1_id'].isna()\n",
    "        missing_team2_ids = match_cards_df['team2_id'].isna()\n",
    "\n",
    "        if not missing_team1_ids.any() and not missing_team2_ids.any():\n",
    "            break\n",
    "\n",
    "        print(f\"Threshold {threshold}. Max Index {max_index}\")\n",
    "\n",
    "        team_ids = match_cards_df[missing_team1_ids | missing_team2_ids].progress_apply(\n",
    "            lambda row: find_closest_team_id_with_index_distance(row, unique_teams, threshold, max_index),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        match_cards_df.loc[missing_team1_ids, 'team1_id'] = team_ids.apply(lambda x: x[0])\n",
    "        match_cards_df.loc[missing_team2_ids, 'team2_id'] = team_ids.apply(lambda x: x[1])\n",
    "\n",
    "        # Decrease threshold and increase index distance\n",
    "        threshold -= 0.02\n",
    "        max_index = math.ceil(max_index * 1.5)\n",
    "\n",
    "        # Stop if threshold is too low\n",
    "        if threshold < 0.7:\n",
    "            break\n",
    "\n",
    "# Apply the progressive matching\n",
    "progressively_match_teams(match_cards_df, unique_teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56567 entries, 0 to 200453\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   team           56567 non-null  object\n",
      " 1   tournament_id  56567 non-null  int64 \n",
      " 2   team_id        56567 non-null  int64 \n",
      " 3   name           56567 non-null  object\n",
      " 4   position       46842 non-null  object\n",
      " 5   flag           31734 non-null  object\n",
      " 6   role_type      56567 non-null  object\n",
      " 7   clean_team     56567 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 3.9+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56567 entries, 0 to 200453\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   team           56567 non-null  object\n",
      " 1   tournament_id  56567 non-null  int64 \n",
      " 2   team_id        56567 non-null  int64 \n",
      " 3   name           56567 non-null  object\n",
      " 4   position       50036 non-null  object\n",
      " 5   flag           48112 non-null  object\n",
      " 6   role_type      56567 non-null  object\n",
      " 7   clean_team     56567 non-null  object\n",
      " 8   unique_id      56567 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Display the initial info of the DataFrame\n",
    "team_members_df.info()\n",
    "\n",
    "# Helper function to find the most common value in a list\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "# Helper function to create lookup dictionary\n",
    "def create_lookup(df, key_cols, value_col):\n",
    "    lookup = defaultdict(list)\n",
    "    for _, row in df[df[value_col].notna()].iterrows():\n",
    "        key = tuple(row[col] for col in key_cols)\n",
    "        lookup[key].append(row[value_col])\n",
    "    return {\n",
    "        key: most_common(values)\n",
    "        for key, values in lookup.items()\n",
    "    }\n",
    "\n",
    "# Impute missing values based on lookup dictionary\n",
    "def impute_missing_values(df, lookup, key_cols, value_col):\n",
    "    for idx, row in df[df[value_col].isna()].iterrows():\n",
    "        key = tuple(row[col] for col in key_cols)\n",
    "        if key in lookup:\n",
    "            df.at[idx, value_col] = lookup[key]\n",
    "\n",
    "# Step 2: Impute missing position values\n",
    "position_lookup = create_lookup(team_members_df, [\"name\", \"flag\", \"role_type\"], \"position\")\n",
    "impute_missing_values(team_members_df, position_lookup, [\"name\", \"flag\", \"role_type\"], \"position\")\n",
    "\n",
    "# Step 3: Impute missing flag values\n",
    "flag_lookup = create_lookup(team_members_df, [\"name\", \"position\", \"role_type\"], \"flag\")\n",
    "impute_missing_values(team_members_df, flag_lookup, [\"name\", \"position\", \"role_type\"], \"flag\")\n",
    "\n",
    "# Step 4: Impute remaining values based on name and role_type alone\n",
    "position_lookup_name = create_lookup(team_members_df, [\"name\", \"role_type\"], \"position\")\n",
    "impute_missing_values(team_members_df, position_lookup_name, [\"name\", \"role_type\"], \"position\")\n",
    "\n",
    "flag_lookup_name = create_lookup(team_members_df, [\"name\", \"role_type\"], \"flag\")\n",
    "impute_missing_values(team_members_df, flag_lookup_name, [\"name\", \"role_type\"], \"flag\")\n",
    "\n",
    "# Step 6: Create a unique ID for combinations of NAME, FLAG, POSITION, and ROLE_TYPE\n",
    "combination_to_id = {}\n",
    "current_id = 1\n",
    "\n",
    "def get_combination_id(row):\n",
    "    global current_id\n",
    "    job = 0 if row[\"position\"] == 0 else 1\n",
    "    key = (\n",
    "        row[\"name\"],\n",
    "        row[\"flag\"] if pd.notna(row[\"flag\"]) else None,\n",
    "        job,\n",
    "        row[\"role_type\"]\n",
    "    )\n",
    "    if key not in combination_to_id:\n",
    "        combination_to_id[key] = current_id\n",
    "        current_id += 1\n",
    "    return combination_to_id[key]\n",
    "\n",
    "team_members_df[\"unique_id\"] = team_members_df.apply(get_combination_id, axis=1)\n",
    "\n",
    "# Display the updated DataFrame info\n",
    "team_members_df.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing matches: 100%|██████████| 16677/16677 [05:55<00:00, 46.93it/s] \n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "config = {\n",
    "    \"base_k\": 100,  # Base K-factor for ELO calculations\n",
    "    \"initial_elo\": 1500.0,  # Initial ELO rating for all players and coaches\n",
    "    \"tier_multiplier_factor_pre_2024\": 12,  # Pre-2024 tier multiplier factor\n",
    "    \"tier_exponent_pre_2024\": 2,  # Pre-2024 tier exponent\n",
    "    \"tier_multiplier_factor_post_2024\": 6,  # Post-2024 tier multiplier factor\n",
    "    \"tier_exponent_post_2024\": 1,  # Post-2024 tier exponent\n",
    "}\n",
    "\n",
    "def calculate_elo_change_common(player_avg_elo, opponent_avg_elo, outcome, base_k, tier_multiplier):\n",
    "    expected_score = 1 / (1 + 10 ** ((opponent_avg_elo - player_avg_elo) / 406))\n",
    "    change = (base_k * tier_multiplier) * (outcome - expected_score)\n",
    "    return change, expected_score\n",
    "\n",
    "def update_elo_ratings(matches_df, members_df, config):\n",
    "    base_k = config[\"base_k\"]\n",
    "    initial_elo = config[\"initial_elo\"]\n",
    "    tier_multiplier_factor_pre_2024 = config[\"tier_multiplier_factor_pre_2024\"]\n",
    "    tier_exponent_pre_2024 = config[\"tier_exponent_pre_2024\"]\n",
    "    tier_multiplier_factor_post_2024 = config[\"tier_multiplier_factor_post_2024\"]\n",
    "    tier_exponent_post_2024 = config[\"tier_exponent_post_2024\"]\n",
    "\n",
    "    # Sort data outside the loop\n",
    "    matches_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "    # Initialize ELO ratings\n",
    "    members_df['elo_before'] = initial_elo\n",
    "    members_df['elo_after'] = initial_elo\n",
    "    members_df['c_elo_before'] = initial_elo\n",
    "    members_df['c_elo_after'] = initial_elo\n",
    "    elo_ratings = {}\n",
    "    coach_elo_ratings = {}\n",
    "\n",
    "    # Drop columns if they already exist\n",
    "    for col in ['team1_avg_elo', 'team2_avg_elo', 'team1_expected_outcome', 'team2_expected_outcome']:\n",
    "        if col in matches_df.columns:\n",
    "            matches_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Initial values for tier multipliers\n",
    "    tier_multiplier_factor = tier_multiplier_factor_pre_2024\n",
    "    tier_exponent = tier_exponent_pre_2024\n",
    "\n",
    "    for _, match in tqdm(matches_df.iterrows(), total=len(matches_df), desc=\"Processing matches\"):\n",
    "        # Pre-fetch match values\n",
    "        match_id = match[\"match_card_id\"]\n",
    "        date = match[\"date\"]\n",
    "        winner = match[\"winner\"]\n",
    "        team1_id = match[\"team1_id\"]\n",
    "        team2_id = match[\"team2_id\"]\n",
    "        tier = match[\"liquipediatier\"]\n",
    "\n",
    "        # Ensure both team1_id and team2_id are present\n",
    "        if pd.isna(team1_id) or pd.isna(team2_id):\n",
    "            continue\n",
    "        \n",
    "        # Get team player IDs once and reuse\n",
    "        team1_players = members_df[(members_df[\"team_id\"] == team1_id) & (members_df[\"role_type\"] == 'player')][\"unique_id\"].tolist()\n",
    "        team2_players = members_df[(members_df[\"team_id\"] == team2_id) & (members_df[\"role_type\"] == 'player')][\"unique_id\"].tolist()\n",
    "        team1_all_members = members_df[(members_df[\"team_id\"] == team1_id) & (members_df[\"role_type\"].isin(['player', 'staff']))][\"unique_id\"].tolist()\n",
    "        team2_all_members = members_df[(members_df[\"team_id\"] == team2_id) & (members_df[\"role_type\"].isin(['player', 'staff']))][\"unique_id\"].tolist()\n",
    "\n",
    "        # Skip matches where either team has no players\n",
    "        if not team1_players or not team2_players:\n",
    "            continue\n",
    "\n",
    "        # Update tier multipliers if the date threshold is crossed\n",
    "        if date >= \"2024-01-01\" and (tier_multiplier_factor != tier_multiplier_factor_post_2024 or tier_exponent != tier_exponent_post_2024):\n",
    "            tier_multiplier_factor = tier_multiplier_factor_post_2024\n",
    "            tier_exponent = tier_exponent_post_2024\n",
    "        \n",
    "        if winner not in [1, 2]:\n",
    "            continue\n",
    "        \n",
    "        tier_multiplier = tier_multiplier_factor / ((tier + 1) ** tier_exponent)\n",
    "        \n",
    "        # Retrieve and set ELOs for team members before the match\n",
    "        for uid in team1_players + team2_players:\n",
    "            if uid not in elo_ratings:\n",
    "                elo_ratings[uid] = initial_elo\n",
    "        \n",
    "        for uid in team1_all_members + team2_all_members:\n",
    "            if uid not in coach_elo_ratings:\n",
    "                coach_elo_ratings[uid] = initial_elo\n",
    "\n",
    "        team1_avg_elo = sum(elo_ratings[uid] for uid in team1_players) / len(team1_players)\n",
    "        team2_avg_elo = sum(elo_ratings[uid] for uid in team2_players) / len(team2_players)\n",
    "        team1_avg_coach_elo = sum(coach_elo_ratings[uid] for uid in team1_all_members) / len(team1_all_members)\n",
    "        team2_avg_coach_elo = sum(coach_elo_ratings[uid] for uid in team2_all_members) / len(team2_all_members)\n",
    "\n",
    "        outcome1 = 1 if winner == 1 else 0\n",
    "\n",
    "        team1_common_change, team1_expected_outcome = calculate_elo_change_common(team1_avg_elo, team2_avg_elo, outcome1, base_k, tier_multiplier)\n",
    "        team2_common_change = -team1_common_change  # The change for team 2 is the inverse of team 1\n",
    "\n",
    "        team1_coach_change, _ = calculate_elo_change_common(team1_avg_coach_elo, team2_avg_coach_elo, outcome1, base_k, tier_multiplier)\n",
    "        team2_coach_change = -team1_coach_change  # The change for team 2 is the inverse of team 1\n",
    "\n",
    "        # Store the average ELOs and expected outcomes in matches_df\n",
    "        matches_df.loc[matches_df['match_card_id'] == match_id, 'team1_avg_elo'] = team1_avg_elo\n",
    "        matches_df.loc[matches_df['match_card_id'] == match_id, 'team2_avg_elo'] = team2_avg_elo\n",
    "        matches_df.loc[matches_df['match_card_id'] == match_id, 'team1_expected_outcome'] = team1_expected_outcome\n",
    "        matches_df.loc[matches_df['match_card_id'] == match_id, 'team2_expected_outcome'] = 1 - team1_expected_outcome\n",
    "\n",
    "        # Update ELOs for players and coaches\n",
    "        for team, team_common_change, team_coach_change, team_players, team_all_members in [\n",
    "            (team1_id, team1_common_change, team1_coach_change, team1_players, team1_all_members),\n",
    "            (team2_id, team2_common_change, team2_coach_change, team2_players, team2_all_members)\n",
    "        ]:\n",
    "            for unique_id in team_players:\n",
    "                player_elo_before = elo_ratings[unique_id]\n",
    "                player_elo_after = player_elo_before + team_common_change\n",
    "                elo_ratings[unique_id] = player_elo_after\n",
    "\n",
    "                members_df.loc[(members_df['unique_id'] == unique_id) & (members_df['team_id'] == team), 'elo_before'] = player_elo_before\n",
    "                members_df.loc[(members_df['unique_id'] == unique_id) & (members_df['team_id'] == team), 'elo_after'] = player_elo_after\n",
    "\n",
    "            for unique_id in team_all_members:\n",
    "                coach_elo_before = coach_elo_ratings[unique_id]\n",
    "                coach_elo_after = coach_elo_before + team_coach_change\n",
    "                coach_elo_ratings[unique_id] = coach_elo_after\n",
    "\n",
    "                members_df.loc[(members_df['unique_id'] == unique_id) & (members_df['team_id'] == team), 'c_elo_before'] = coach_elo_before\n",
    "                members_df.loc[(members_df['unique_id'] == unique_id) & (members_df['team_id'] == team), 'c_elo_after'] = coach_elo_after\n",
    "\n",
    "# Usage example with match_cards_df, team_members_df, and tournament_info_df already loaded\n",
    "update_elo_ratings(match_cards_df, team_members_df, config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
